{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f6d199",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Using cached onnxruntime-1.14.1-cp39-cp39-win_amd64.whl (6.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime) (21.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime) (1.24.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime) (1.10.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime) (23.3.3)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->onnxruntime) (3.0.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.4.1)\n",
      "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63407bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded <onnxruntime.capi.onnxruntime_inference_collection.InferenceSession object at 0x000002109500A220>\n",
      "capture device is open: True\n",
      "Text of plate is: Text of plate is:  \n",
      " 1\n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  4\n",
      "Text of plate is:  \n",
      "Text of plate is:  4\n",
      "Text of plate is:  4\n",
      "Text of plate is:  \n",
      "Text of plate is:  \n",
      "Text of plate is:  F\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15164\\3638021021.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mfps_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mfps_diff_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfps_end_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfps_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfps_diff_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mfps_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfps_end_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mfps_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"FPS:{:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text of plate is:  \n",
      "Text of plate is:  G\n",
      "Text of plate is:  \n",
      "Text of plate is:  \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pytesseract as pt\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pt.pytesseract.tesseract_cmd=r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "\n",
    "#os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;tcp\"\n",
    "\n",
    "ort_session = ort.InferenceSession('best.onnx')\n",
    "print(\"Model Loaded\", ort_session)\n",
    "\n",
    "net = ort_session\n",
    "\n",
    "   # Function getdetection\n",
    "    \n",
    "def get_detections(img, ort_session):\n",
    "    image = img.copy()\n",
    "    row, col, d = image.shape\n",
    "\n",
    "    max_rc = max(row, col)\n",
    "    input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "    input_image[0:row, 0:col] = image\n",
    "\n",
    "    input_image_resized = cv2.resize(input_image, (INPUT_WIDTH, INPUT_HEIGHT))\n",
    "    input_image_resized = input_image_resized.transpose(2, 0, 1)\n",
    "    input_image_resized = input_image_resized.reshape(1, 3, INPUT_WIDTH, INPUT_HEIGHT).astype('float32')\n",
    "    input_image_resized /= 255.0\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: input_image_resized}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    detections = ort_outs[0][0]\n",
    "\n",
    "    return input_image, detections\n",
    "\n",
    "   # function non max suression\n",
    "\n",
    "def non_maximum_suppression(input_image, detections):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "\n",
    "    image_w, image_h = input_image.shape[:2]\n",
    "    x_factor = image_w / INPUT_WIDTH\n",
    "    y_factor = image_h / INPUT_HEIGHT\n",
    "\n",
    "    for i in range(len(detections)):\n",
    "        row = detections[i]\n",
    "        confidence = row[4]\n",
    "        if confidence > 0.6:\n",
    "            class_score = row[5]\n",
    "            if class_score > 0.25:\n",
    "                cx, cy, w, h = row[0:4]\n",
    "\n",
    "                left = int((cx - 0.5 * w) * x_factor)\n",
    "                top = int((cy - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "\n",
    "                confidences.append(confidence)\n",
    "                boxes.append(box)\n",
    "\n",
    "    boxes_np = np.array(boxes).tolist()\n",
    "    confidences_np = np.array(confidences).tolist()\n",
    "    try:\n",
    "        index = cv2.dnn.NMSBoxes(boxes_np, confidences_np, 0.55, 0.75).flatten()\n",
    "    except:\n",
    "        index = cv2.dnn.NMSBoxes(boxes_np, confidences_np, 0.55, 0.75)\n",
    "    return boxes_np, confidences_np, index\n",
    "\n",
    "  # function text extraction\n",
    "\n",
    "def extract_text(image, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "\n",
    "    if 0 in roi.shape:\n",
    "        return ''\n",
    "    else:\n",
    "        text = pt.image_to_string(roi, lang='eng', config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "        text = text.strip()\n",
    "        print(\"Text of plate is: \", text)\n",
    "        return text\n",
    "\n",
    " # functioon drawing   \n",
    "\n",
    "def drawings(image, boxes_np, confidences_np, index):\n",
    "    for ind in index:\n",
    "        x, y, w, h = boxes_np[ind]\n",
    "        bb_conf = confidences_np[ind]\n",
    "        conf_text = 'plate: {:.0f}%'.format(bb_conf * 100)\n",
    "        license_text = extract_text(image, boxes_np[ind])\n",
    "\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "        cv2.rectangle(image, (x, y - 30), (x + w, y), (255, 0, 255), -1)\n",
    "        cv2.rectangle(image, (x, y + h), (x + w, y + h + 30), (0, 0, 0), -1)\n",
    "\n",
    "        cv2.putText(image, conf_text, (x, y - 13), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(image, license_text, (x, y + h + 27), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    return image\n",
    "    \n",
    "    \n",
    "    \n",
    "def yolo_predictions(img, ort_session):\n",
    "    input_image, detections = get_detections(img, ort_session)\n",
    "    boxes_np, confidences_np, index = non_maximum_suppression(input_image, detections)\n",
    "    result_img = drawings(img, boxes_np, confidences_np, index)\n",
    "    return result_img\n",
    "\n",
    "def process_frame(frame):\n",
    "    frame = cv2.resize(frame, (600, 400))\n",
    "    result = yolo_predictions(frame, net)\n",
    "    return result\n",
    "\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=3)  # Adjust max_workers based on your CPU core count\n",
    "\n",
    "cap = cv2.VideoCapture(\"last_video.mp4\")\n",
    "\n",
    "print(\"capture device is open: \" + str(cap.isOpened()))\n",
    "fps_start_time = time.time()\n",
    "fps = 0\n",
    "\n",
    "frame_futures = []\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame_future = executor.submit(process_frame, frame)\n",
    "    frame_futures.append(frame_future)\n",
    "    \n",
    "    # Process the oldest frame\n",
    "    if len(frame_futures) > 4:  # Adjust the buffer size based on your CPU core count\n",
    "        result = frame_futures.pop(0).result()\n",
    "        fps_end_time = time.time()\n",
    "        fps_diff_time = fps_end_time - fps_start_time\n",
    "        fps = 1 / fps_diff_time\n",
    "        fps_start_time = fps_end_time\n",
    "        fps_text = \"FPS:{:.2f}\".format(fps)\n",
    "        cv2.putText(result, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 255), 1)\n",
    "        cv2.imshow(\"webcam\", result)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Clean up\n",
    "executor.shutdown(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0c5e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3904\\572246782.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytesseract\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pytesseract as pt\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "#os.chdir(\"/Users/PranavGupta/Downloads/plate_copy\")\n",
    "\n",
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;tcp\"\n",
    "\n",
    "ort_session = ort.InferenceSession('best.onnx')\n",
    "print(\"Model Loaded\", ort_session)\n",
    "\"\"\"\n",
    "net = ort_session\n",
    "\n",
    "def get_detections(img, ort_session):\n",
    "    image = img.copy()\n",
    "    row, col, d = image.shape\n",
    "\n",
    "    max_rc = max(row, col)\n",
    "    input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "    input_image[0:row, 0:col] = image\n",
    "\n",
    "    input_image_resized = cv2.resize(input_image, (INPUT_WIDTH, INPUT_HEIGHT))\n",
    "    input_image_resized = input_image_resized.transpose(2, 0, 1)\n",
    "    input_image_resized = input_image_resized.reshape(1, 3, INPUT_WIDTH, INPUT_HEIGHT).astype('float32')\n",
    "    input_image_resized /= 255.0\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: input_image_resized}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    detections = ort_outs[0][0]\n",
    "\n",
    "    return input_image, detections\n",
    "\n",
    "def non_maximum_suppression(input_image, detections):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "\n",
    "    image_w, image_h = input_image.shape[:2]\n",
    "    x_factor = image_w / INPUT_WIDTH\n",
    "    y_factor = image_h / INPUT_HEIGHT\n",
    "\n",
    "    for i in range(len(detections)):\n",
    "        row = detections[i]\n",
    "        confidence = row[4]\n",
    "        if confidence > 0.6:\n",
    "            class_score = row[5]\n",
    "            if class_score > 0.25:\n",
    "                cx, cy, w, h = row[0:4]\n",
    "\n",
    "                left = int((cx - 0.5 * w) * x_factor)\n",
    "                top = int((cy - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "\n",
    "                confidences.append(confidence)\n",
    "                boxes.append(box)\n",
    "\n",
    "    boxes_np = np.array(boxes).tolist()\n",
    "    confidences_np = np.array(confidences).tolist()\n",
    "    try:\n",
    "        index = cv2.dnn.NMSBoxes(boxes_np, confidences_np, 0.55, 0.75).flatten()\n",
    "    except:\n",
    "        index = cv2.dnn.NMSBoxes(boxes_np, confidences_np, 0.55, 0.75)\n",
    "    return boxes_np, confidences_np, index\n",
    "\n",
    "def extract_text(image, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "\n",
    "    if 0 in roi.shape:\n",
    "        return ''\n",
    "    else:\n",
    "        text = pt.image_to_string(roi, lang='eng', config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "        text = text.strip()\n",
    "        print(\"Text of plate is: \", text)\n",
    "        return text\n",
    "\n",
    "def drawings(image, boxes_np, confidences_np, index):\n",
    "    for ind in index:\n",
    "        x, y, w, h = boxes_np[ind]\n",
    "        bb_conf = confidences_np[ind]\n",
    "        conf_text = 'plate: {:.0f}%'.format(bb_conf * 100)\n",
    "        license_text = extract_text(image, boxes_np[ind])\n",
    "\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "        cv2.rectangle(image, (x, y - 30), (x + w, y), (255, 0, 255), -1)\n",
    "        cv2.rectangle(image, (x, y + h), (x + w, y + h + 30), (0, 0, 0), -1)\n",
    "\n",
    "        cv2.putText(image, conf_text, (x, y - 13), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(image, license_text, (x, y + h + 27), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "def yolo_predictions(img, ort_session):\n",
    "    input_image, detections = get_detections(img, ort_session)\n",
    "    boxes_np, confidences_np, index = non_maximum_suppression(input_image, detections)\n",
    "    result_img = drawings(img, boxes_np, confidences_np, index)\n",
    "    return result_img\n",
    "\n",
    "def process_frame(frame):\n",
    "    frame = cv2.resize(frame, (600, 400))\n",
    "    result = yolo_predictions(frame, net)\n",
    "    return result\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=3)  # Adjust max_workers based on your CPU core count\n",
    "\n",
    "cap = cv2.VideoCapture(\"last_video.mp4\")\n",
    "\n",
    "print(\"capture device is open: \" + str(cap.isOpened()))\n",
    "fps_start_time = time.time()\n",
    "fps = 0\n",
    "\n",
    "frame_futures = []\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame_future = executor.submit(process_frame, frame)\n",
    "    frame_futures.append(frame_future)\n",
    "\n",
    "    # Process the oldest frame\n",
    "    if len(frame_futures) > 4:  # Adjust the buffer size based on your CPU core count\n",
    "        result = frame_futures.pop(0).result()\n",
    "        fps_end_time = time.time()\n",
    "        fps_diff_time = fps_end_time - fps_start_time\n",
    "        fps = 1 / fps_diff_time\n",
    "        fps_start_time = fps_end_time\n",
    "        fps_text = \"FPS:{:.2f}\".format(fps)\n",
    "        cv2.putText(result, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 255), 1)\n",
    "        cv2.imshow(\"webcam\", result)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Clean up\n",
    "executor.shutdown(wait=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b8696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
